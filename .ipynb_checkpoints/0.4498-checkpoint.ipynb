{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LinearRegression,LogisticRegression,Ridge,Lasso\n",
    "from sklearn.model_selection import GridSearchCV,train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.ensemble import RandomForestClassifier,RandomForestRegressor\n",
    "from xgboost import XGBRegressor,XGBClassifier\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.svm import LinearSVC,LinearSVR,SVC,SVR\n",
    "from scipy.stats import norm,skew\n",
    "\n",
    "# Setting the number of columns to display\n",
    "pd.set_option('display.max_columns', None)\n",
    "# year\n",
    "yr=2014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities=pd.read_csv(\"WPrelimData2018/WCities_PrelimData2018.csv\")\n",
    "game_cities=pd.read_csv(\"WPrelimData2018/WGameCities_PrelimData2018.csv\")\n",
    "\n",
    "tourney_seeds=pd.read_csv(\"WDataFiles/WNCAATourneySeeds.csv\")\n",
    "\n",
    "regular_season_results=pd.read_csv(\"WPrelimData2018/WRegularSeasonCompactResults_PrelimData2018.csv\")\n",
    "detailed_regular_season=pd.read_csv(\"WPrelimData2018/WRegularSeasonDetailedResults_PrelimData2018.csv\")\n",
    "\n",
    "tourney_results=pd.read_csv(\"WPrelimData2018/WNCAATourneyCompactResults_PrelimData2018.csv\")\n",
    "detailed_tourney=pd.read_csv(\"WPrelimData2018/WNCAATourneyDetailedResults_PrelimData2018.csv\")\n",
    "\n",
    "\n",
    "sample_submission=pd.read_csv(\"WDataFiles/WSampleSubmissionStage1.csv\")\n",
    "\n",
    "print(\"Regular season results\",regular_season_results.shape)\n",
    "print(\"Tourney results\",tourney_results.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tourney_results=pd.concat([tourney_results,regular_season_results],axis=0)\n",
    "# tourney_results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for extraction of seed and region\n",
    "def extract_seedint(seed):\n",
    "    k=int(seed[1:])\n",
    "    return k;\n",
    "def region(seed):\n",
    "    return seed[0];\n",
    "tourney_seeds['seed_int']=tourney_seeds['Seed'].apply(extract_seedint)\n",
    "tourney_seeds['region']=tourney_seeds['Seed'].apply(region)\n",
    "tourney_seeds.drop(columns=['Seed'],inplace=True)\n",
    "tourney_seeds.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merging the tournament results\n",
    "winseeds = tourney_seeds.rename(columns={'TeamID':'WTeamID', 'seed_int':'WSeed','region':'WRegion'})\n",
    "lossseeds = tourney_seeds.rename(columns={'TeamID':'LTeamID', 'seed_int':'LSeed','region':'LRegion'})\n",
    "df_dummy = pd.merge(left=tourney_results, right=winseeds, how='left', on=['Season', 'WTeamID'])\n",
    "tourney_results= pd.merge(left=df_dummy, right=lossseeds,how='left',on=['Season', 'LTeamID'])\n",
    "tourney_results.WSeed.fillna(0,inplace=True)\n",
    "tourney_results.LSeed.fillna(0,inplace=True)\n",
    "tourney_results.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wins=tourney_results.loc[tourney_results['Season']<yr,['Season','WSeed','LSeed','WScore','LScore']]\n",
    "wins['SeedDiff']=wins['WSeed']-wins['LSeed']\n",
    "wins['ScoreDiff']=wins['WScore']-wins['LScore']\n",
    "wins.drop(columns=['WSeed','LSeed','WScore','LScore'],inplace=True)\n",
    "\n",
    "wins['Result']=1\n",
    "wins['Result']=wins['Result'].astype(int)\n",
    "\n",
    "losses=-wins\n",
    "losses['Result']=0\n",
    "losses['Season']=-losses['Season']\n",
    "\n",
    "data=pd.concat([wins,losses],axis=0)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=data.iloc[:,[1]].values\n",
    "y_train=data.iloc[:,2].values\n",
    "# log transform\n",
    "# y_train=(data.iloc[:,2].values)\n",
    "\n",
    "print(X_train.shape,y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train,X_val,y_train,y_val=train_test_split(X_train,y_train,test_size=0.1,random_state=42,shuffle=True)\n",
    "print(\"For regression \")\n",
    "print(\"The training shape is\",X_train.shape,\" and the label shape is\",y_train.shape)\n",
    "print(\"The validation shape is\",X_val.shape,\" and the label shape is\",y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My plan is to predict the score differences and this can be used to predict the score differences in the test data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=LinearRegression()\n",
    "lr.fit(X_train,y_train)\n",
    "print(\"The training Error is\",lr.score(X_train,y_train))\n",
    "print(\"The validation error is\",lr.score(X_val,y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf=RandomForestRegressor(random_state=42)\n",
    "rf.fit(X_train,y_train)\n",
    "print(\"The training Score is\",rf.score(X_train,y_train))\n",
    "print(\"The validation Score is\",rf.score(X_val,y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgr=XGBRegressor(random_state=42)\n",
    "xgr.fit(X_train,y_train)\n",
    "print(\"The training Score is\",xgr.score(X_train,y_train))\n",
    "print(\"The validation Score is\",xgr.score(X_val,y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr=SVR()\n",
    "svr.fit(X_train,y_train)\n",
    "print(\"training Score\",svr.score(X_train,y_train))\n",
    "print(\"validation score\",svr.score(X_val,y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge=Ridge()\n",
    "ridge.fit(X_train,y_train)\n",
    "print(\"The training Score is\",ridge.score(X_train,y_train))\n",
    "print(\"The validation Score is\",ridge.score(X_val,y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso=Lasso()\n",
    "lasso.fit(X_train,y_train)\n",
    "print(\"The training Score is\",lasso.score(X_train,y_train))\n",
    "print(\"The validation Score is\",lasso.score(X_val,y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will choose the randomforest regressor(just a try!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_data=data.iloc[:,1:2].values\n",
    "data['DiffbyRegressor']=(xgr.predict(pred_data))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will build a classifier on the data using Season,SeedDiff,ScoreDiff by regressor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=data.iloc[:,[1,4]].values\n",
    "y_train=data.iloc[:,3].values\n",
    "print(X_train.shape,y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_val,y_train,y_val=train_test_split(X_train,y_train,test_size=0.1,random_state=42,shuffle=True)\n",
    "\n",
    "print(\"The training shape is\",X_train.shape,\" and the label shape is\",y_train.shape)\n",
    "print(\"The validation shape is\",X_val.shape,\" and the label shape is\",y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=LogisticRegression()\n",
    "lr.fit(X_train,y_train)\n",
    "print(\"The training log loss is\",log_loss(y_train,lr.predict_proba(X_train)[:,1]))\n",
    "print(\"The validation log los is\",log_loss(y_val,lr.predict_proba(X_val)[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgc=XGBClassifier(n_estimators=100,random_state=42)\n",
    "xgc.fit(X_train,y_train)\n",
    "print(\"The training log loss is\",log_loss(y_train,xgc.predict_proba(X_train)[:,1]))\n",
    "print(\"The validation log los is\",log_loss(y_val,xgc.predict_proba(X_val)[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The training loss of the ensemble is\",log_loss(y_train,0.5*xgc.predict_proba(X_train)[:,1]+0.5*lr.predict_proba(X_train)[:,1]))\n",
    "print(\"The validation loss of the ensemble is\",log_loss(y_val,0.5*xgc.predict_proba(X_val)[:,1]+0.5*lr.predict_proba(X_val)[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEST PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=pd.DataFrame(columns=['Season','WTeamID','LTeamID'])\n",
    "for i in sample_submission.index:\n",
    "    season,wid,lid=map(int,sample_submission['ID'][i].split(\"_\"))\n",
    "    test.loc[i,'Season']=season\n",
    "    test.loc[i,'WTeamID']=wid\n",
    "    test.loc[i,'LTeamID']=lid\n",
    "\n",
    "test['Season']=test['Season'].astype(int)\n",
    "test['WTeamID']=test['WTeamID'].astype(int)\n",
    "test['LTeamID']=test['LTeamID'].astype(int)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dummy=pd.merge(left=test,right=winseeds,how='left',on=['Season','WTeamID'])\n",
    "test=pd.merge(left=df_dummy,right=lossseeds,how='left',on=['Season','LTeamID'])\n",
    "\n",
    "test.drop(columns=['WRegion','LRegion'],inplace=True)\n",
    "test['SeedDiff']=test['WSeed']-test['LSeed']\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# predictions of regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=test.iloc[:,[5]].values\n",
    "test['DiffbyRegressor']=xgr.predict(X_test)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## predictions of classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=test.iloc[:,[5,6]].values\n",
    "sample_submission['Pred']=xgc.predict_proba(X_test)[:,1]\n",
    "sample_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission.to_csv(\"Trying_something_new.csv\",index=False)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=test.iloc[:,[5,6]].values\n",
    "sample_submission['Pred']=0.5*xgc.predict_proba(X_test)[:,1]+0.5*lr.predict_proba(X_test)[:,1]\n",
    "sample_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission.to_csv(\"Trying_something_new_ensemble.csv\")\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result of each submission is given in combo.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
